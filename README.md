# GitHub Repository Q&A Assistant

A Streamlit app that allows you to ask questions about any GitHub repository. The app clones the repository, processes its code files, stores embeddings using Pinecone, and generates answers using Google's Generative AI model.

## Features

- **Clone GitHub Repositories**: Input the URL of any public GitHub repository to clone it locally.
- **Process Code Files**: Automatically processes common code file types and splits them into manageable chunks.
- **Generate Embeddings**: Uses `sentence-transformers` to create embeddings of the code chunks.
- **Store Embeddings with Pinecone**: Stores the embeddings in a Pinecone index for efficient retrieval.
- **Question Answering**: Ask questions about the repository's code, and get answers generated by Google's Generative AI model.

## Prerequisites

- Python 3.6 or higher
- [Streamlit](https://streamlit.io/) installed
- Account and API keys for:
  - [Pinecone](https://www.pinecone.io/)
  - [Google Generative AI](https://developers.google.com/ai/generative-ai)
- Git installed on your system

## Installation

1. **Clone this repository**

   ```bash
   git clone https://github.com/yourusername/your-repo-name.git
   cd your-repo-name
   ```

2. **Create and activate a virtual environment (optional but recommended)**

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. **Install the required Python packages**

   ```bash
   pip install -r requirements.txt
   ```

   If `requirements.txt` is not provided, install the packages manually:

   ```bash
   pip install os shutil gitpython openai pinecone-client streamlit tiktoken sentence-transformers google-generativeai
   ```

4. **Set up API keys**

   Create a file named `secrets.toml` inside a folder named `.streamlit` at the root of your project:

   ```bash
   mkdir .streamlit
   nano .streamlit/secrets.toml
   ```

   Add your API keys to `secrets.toml`:

   ```toml
   [secrets]
   [secrets.pinecone]
   api_key = "YOUR_PINECONE_API_KEY"

   [secrets.gemini]
   api_key = "YOUR_GOOGLE_GENERATIVE_AI_API_KEY"
   ```

   Replace `"YOUR_PINECONE_API_KEY"` and `"YOUR_GOOGLE_GENERATIVE_AI_API_KEY"` with your actual API keys.

## Usage

1. **Run the Streamlit app**

   ```bash
   streamlit run app.py
   ```

2. **Interact with the app**

   - **Enter the GitHub repository URL**: Input the URL of the GitHub repository you want to analyze.
   - **Process the Repository**: Click on the "Process Repository" button to clone and process the repository.
     - The app will clone the repository to a local directory.
     - It will read code files (e.g., `.py`, `.js`, `.java`, etc.), split them into chunks, and generate embeddings.
     - Embeddings are stored in a Pinecone index for later retrieval.
   - **Ask a Question**: Enter a question about the repository in the provided text input.
   - **Get the Answer**: Click on the "Get Answer" button to retrieve an answer.
     - The app retrieves relevant code chunks based on your question.
     - It uses Google's Generative AI model to generate an answer using the retrieved context.

## Supported File Types

The app processes files with the following extensions:

- `.py`, `.js`, `.java`, `.c`, `.cpp`, `.rb`, `.go`, `.ts`, `.cs`, `.php`, `.swift`

## How It Works

- **Cloning Repositories**: Uses `GitPython` to clone the repository to a local directory.
- **Processing Files**: 
  - Reads code files and decodes them using UTF-8 (ignoring errors).
  - Splits the text into chunks of up to 500 tokens using `tiktoken`.
- **Generating Embeddings**:
  - Uses `sentence-transformers` with the model `all-MiniLM-L6-v2` to generate embeddings.
- **Storing Embeddings**:
  - Stores embeddings in a Pinecone index with cosine similarity metric.
  - The index is named based on the sanitized repository name.
- **Retrieving Context**:
  - Retrieves the top relevant code chunks from Pinecone based on the question embedding.
- **Answer Generation**:
  - Uses Google's Generative AI model `gemini-pro` to generate an answer.
  - The model takes the retrieved context and the question as input.

## Troubleshooting

- **Pinecone Index Initialization**: If you encounter issues with the Pinecone index not initializing, ensure you have sufficient permissions and wait for at least 30 seconds after creation.
- **API Key Errors**: Make sure your API keys are correctly entered in the `secrets.toml` file.
- **File Reading Errors**: The app ignores errors when decoding files. If certain files are not processed, check their encoding or file type.

## Dependencies

- `os`
- `shutil`
- `gitpython`
- `openai`
- `pinecone-client`
- `streamlit`
- `tiktoken`
- `sentence-transformers`
- `google-generativeai`


## Acknowledgments

- [Streamlit](https://streamlit.io/) for the web app framework.
- [Pinecone](https://www.pinecone.io/) for vector similarity search.
- [SentenceTransformers](https://www.sbert.net/) for embedding generation.
- [Google Generative AI](https://developers.google.com/ai/generative-ai) for the language model.

---

Feel free to contribute to this project by opening issues or submitting pull requests.
